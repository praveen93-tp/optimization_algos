# optimization_algos
 Contains implementations of loss functions from scratch - logistic, hinge, least_square etc
 
 Contains implementations of gradient descent variant algorithms:
   1) gradient_descent_fixed_learning_rate
   2) gradient_descent_armijo_line_search
   3) accelerated_gradient_descent
   4) conjugate_gradient_descent
   5) brazillia_bowrein_step_gradient_descent
   6) proximal_gradient_descent
   7) gradient_descent_with_momentum
   8) nesterovs_gradient_descent
   9) adagarad
   
